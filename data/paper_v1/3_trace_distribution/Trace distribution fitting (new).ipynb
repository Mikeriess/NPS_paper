{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def experiment(X_train, X_test):\n",
    "    \"\"\"\n",
    "    A single bootstrap experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    #########################\n",
    "    # Training\n",
    "    k_size = 1\n",
    "\n",
    "    #Train the baseline model\n",
    "    model_test = pomegranate.MarkovChain.from_samples(X=X_test, k=k_size)\n",
    "    \n",
    "    #Train the model\n",
    "    model_train = pomegranate.MarkovChain.from_samples(X=X_train, k=k_size)\n",
    "    \n",
    "    #########################\n",
    "    # transforming\n",
    "    test_trans = pd.DataFrame(model_test.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "    test_trans[\"prob\"] = pd.to_numeric(test_trans[\"prob\"], downcast=\"float\")\n",
    "    test_prob = test_trans[\"prob\"]\n",
    "    \n",
    "\n",
    "    train_trans = pd.DataFrame(model_train.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "    train_trans[\"prob\"] = pd.to_numeric(train_trans[\"prob\"], downcast=\"float\")\n",
    "    train_prob = train_trans[\"prob\"]\n",
    "    \n",
    "    \"\"\"\n",
    "    Check that they are the same?!\n",
    "    \"\"\"\n",
    "    \n",
    "    kl_error, euc_error = 999, 999\n",
    "    \n",
    "    if train_trans[\"from\"].values.tolist() == test_trans[\"from\"].values.tolist():\n",
    "        if train_trans[\"to\"].values.tolist() == test_trans[\"to\"].values.tolist():\n",
    "            \n",
    "            #add small value\n",
    "            train_prob = train_prob + 10e-5\n",
    "            test_prob = test_prob + 10e-5\n",
    "\n",
    "            #Normalize\n",
    "            train_prob = train_prob/np.sum(train_prob)\n",
    "            test_prob = test_prob/np.sum(test_prob)\n",
    "\n",
    "            #########################\n",
    "            # evaluation\n",
    "            kl_error = kl_divergence(train_prob.values, test_prob.values)\n",
    "            euc_error = euclidean_distance(train_prob.values, test_prob.values)\n",
    "    \n",
    "    #print(kl_error,euc_error)\n",
    "    \n",
    "    return kl_error, euc_error"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Inspect the resulting graphs\n",
    "\"\"\"\n",
    "import networkx as nx\n",
    "\n",
    "def generate_edgelist(trace):    \n",
    "    E = [[i[0],j] for i in trace for j in i[1:]]    \n",
    "    return E\n",
    "\n",
    "def generate_adj_matrix(edgelist):\n",
    "    from networkx import from_edgelist, to_numpy_matrix\n",
    "    G = from_edgelist(edgelist)\n",
    "    matrix = to_numpy_matrix(G)\n",
    "    return matrix\n",
    "\n",
    "data = predictions #traindata\n",
    "\n",
    "#generate edgelist\n",
    "E1 = generate_edgelist(data)\n",
    "G1 = nx.from_edgelist(E1)\n",
    "Adj1 = generate_adj_matrix(E1)\n",
    "print(\"actual\",Adj1)\n",
    "\n",
    "\n",
    "#generate edgelist\n",
    "E2 = generate_edgelist(predictions)\n",
    "G2 = nx.from_edgelist(E2)\n",
    "Adj2 = generate_adj_matrix(E2)\n",
    "print(\"pred\",Adj2)\n",
    "\n",
    "#if same size:\n",
    "Adj1 - Adj2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subax1 = plt.subplot(121)\n",
    "nx.draw(G1, with_labels=True, font_weight='bold')\n",
    "\n",
    "subax2 = plt.subplot(122)\n",
    "nx.draw_shell(G2, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "\"\"\"\n",
    "Inspect the resulting graphs\n",
    "\"\"\"\n",
    "\n",
    "def generate_edgelist(trace):    \n",
    "    E = [[i[0],j] for i in trace for j in i[1:]]    \n",
    "    return E\n",
    "\n",
    "def generate_adj_matrix(edgelist):\n",
    "    from networkx import from_edgelist, to_numpy_matrix\n",
    "    G = from_edgelist(edgelist)\n",
    "    matrix = to_numpy_matrix(G)\n",
    "    return matrix\n",
    "    \n",
    "\"\"\"\n",
    "Generate a DIRECTED graph with networkx\n",
    "\"\"\"\n",
    "\n",
    "data = predictions #traindata\n",
    "#data = traindata #traindata\n",
    "\n",
    "EDGES = generate_edgelist(data)\n",
    "EDGES = [tuple(x) for x in EDGES]\n",
    "\n",
    "\"\"\"\n",
    "Generate directed graph\n",
    "\"\"\"\n",
    "\n",
    "g = nx.DiGraph((x, y, {'weight': v}) for (x, y), v in Counter(EDGES).items())\n",
    "print(*g.edges(data=True), sep='\\n')\n",
    "\n",
    "\"\"\"\n",
    "Draw directed graph\n",
    "\"\"\"\n",
    "nx.draw_networkx(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_type</th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_tasksubtype</th>\n",
       "      <th>ressource</th>\n",
       "      <th>ressource_role</th>\n",
       "      <th>case_owner_role</th>\n",
       "      <th>case_topic</th>\n",
       "      <th>case_requires_rework__c</th>\n",
       "      <th>case_closure_code__c</th>\n",
       "      <th>...</th>\n",
       "      <th>task_count</th>\n",
       "      <th>task_number</th>\n",
       "      <th>date_case_created</th>\n",
       "      <th>date_case_closed</th>\n",
       "      <th>date_task_created</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1485898</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>1</td>\n",
       "      <td>Email</td>\n",
       "      <td>y_7</td>\n",
       "      <td>b_1</td>\n",
       "      <td>b_1</td>\n",
       "      <td>d_2</td>\n",
       "      <td>False</td>\n",
       "      <td>Changed subscription</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-12 11:40:54</td>\n",
       "      <td>2018-02-18 23:01:09+00:00</td>\n",
       "      <td>2018-02-12 11:42:22+00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1485898</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>2</td>\n",
       "      <td>Email</td>\n",
       "      <td>y_7</td>\n",
       "      <td>b_1</td>\n",
       "      <td>b_1</td>\n",
       "      <td>d_2</td>\n",
       "      <td>False</td>\n",
       "      <td>Changed subscription</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-12 11:40:54</td>\n",
       "      <td>2018-02-18 23:01:09+00:00</td>\n",
       "      <td>2018-02-12 11:57:20+00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491822</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>5</td>\n",
       "      <td>Email</td>\n",
       "      <td>y_9</td>\n",
       "      <td>i_1</td>\n",
       "      <td>i_1</td>\n",
       "      <td>d_2</td>\n",
       "      <td>False</td>\n",
       "      <td>Information/guidance given</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-20 10:17:59</td>\n",
       "      <td>2018-03-05 23:00:51+00:00</td>\n",
       "      <td>2018-02-20 10:20:20+00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491822</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>10</td>\n",
       "      <td>Email</td>\n",
       "      <td>y_9</td>\n",
       "      <td>i_1</td>\n",
       "      <td>i_1</td>\n",
       "      <td>d_2</td>\n",
       "      <td>False</td>\n",
       "      <td>Information/guidance given</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-20 10:17:59</td>\n",
       "      <td>2018-03-05 23:00:51+00:00</td>\n",
       "      <td>2018-02-21 11:19:09+00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491822</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>19</td>\n",
       "      <td>Email</td>\n",
       "      <td>y_9</td>\n",
       "      <td>i_1</td>\n",
       "      <td>i_1</td>\n",
       "      <td>d_2</td>\n",
       "      <td>False</td>\n",
       "      <td>Information/guidance given</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-20 10:17:59</td>\n",
       "      <td>2018-03-05 23:00:51+00:00</td>\n",
       "      <td>2018-02-23 10:30:44+00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id        case_type  task_id task_tasksubtype ressource  \\\n",
       "0  1485898  Service Request        1            Email       y_7   \n",
       "1  1485898  Service Request        2            Email       y_7   \n",
       "2  1491822  Service Request        5            Email       y_9   \n",
       "3  1491822  Service Request       10            Email       y_9   \n",
       "4  1491822  Service Request       19            Email       y_9   \n",
       "\n",
       "  ressource_role case_owner_role case_topic  case_requires_rework__c  \\\n",
       "0            b_1             b_1        d_2                    False   \n",
       "1            b_1             b_1        d_2                    False   \n",
       "2            i_1             i_1        d_2                    False   \n",
       "3            i_1             i_1        d_2                    False   \n",
       "4            i_1             i_1        d_2                    False   \n",
       "\n",
       "         case_closure_code__c  ... task_count  task_number  \\\n",
       "0        Changed subscription  ...          2            1   \n",
       "1        Changed subscription  ...          2            2   \n",
       "2  Information/guidance given  ...          3            1   \n",
       "3  Information/guidance given  ...          3            2   \n",
       "4  Information/guidance given  ...          3            3   \n",
       "\n",
       "     date_case_created           date_case_closed          date_task_created  \\\n",
       "0  2018-02-12 11:40:54  2018-02-18 23:01:09+00:00  2018-02-12 11:42:22+00:00   \n",
       "1  2018-02-12 11:40:54  2018-02-18 23:01:09+00:00  2018-02-12 11:57:20+00:00   \n",
       "2  2018-02-20 10:17:59  2018-03-05 23:00:51+00:00  2018-02-20 10:20:20+00:00   \n",
       "3  2018-02-20 10:17:59  2018-03-05 23:00:51+00:00  2018-02-21 11:19:09+00:00   \n",
       "4  2018-02-20 10:17:59  2018-03-05 23:00:51+00:00  2018-02-23 10:30:44+00:00   \n",
       "\n",
       "   year  month  day  weekday hour  \n",
       "0  2018      2   12        0   11  \n",
       "1  2018      2   12        0   11  \n",
       "2  2018      2   20        1   10  \n",
       "3  2018      2   21        2   11  \n",
       "4  2018      2   23        4   10  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../Data/Data/Strata_Train_NPS_cases/Train_NPS_evlog.csv\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_topic</th>\n",
       "      <th>task_number</th>\n",
       "      <th>task_tasksubtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1485898</td>\n",
       "      <td>d_2</td>\n",
       "      <td>1</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1485898</td>\n",
       "      <td>d_2</td>\n",
       "      <td>2</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491822</td>\n",
       "      <td>d_2</td>\n",
       "      <td>1</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491822</td>\n",
       "      <td>d_2</td>\n",
       "      <td>2</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491822</td>\n",
       "      <td>d_2</td>\n",
       "      <td>3</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id case_topic  task_number task_tasksubtype\n",
       "0  1485898        d_2            1            Email\n",
       "1  1485898        d_2            2            Email\n",
       "2  1491822        d_2            1            Email\n",
       "3  1491822        d_2            2            Email\n",
       "4  1491822        d_2            3            Email"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"case_id\",\"case_topic\",\"task_number\",\"task_tasksubtype\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into a one-dimensional array with variable-length traces. \n",
    "\n",
    "### Add absorption state \"END\" to the trace (multiple times, to avoid HOMC problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\anaconda3\\envs\\TF2_CUD11_CRM_PAPER\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array(['Interaction', 'Email', 'Email', 'END', 'END', 'END', 'END', 'END'],\n",
       "      dtype=object),\n",
       "       array(['Interaction', 'Email', 'END', 'END', 'END', 'END', 'END'],\n",
       "      dtype=object),\n",
       "       array(['Interaction', 'Email', 'END', 'END', 'END', 'END', 'END'],\n",
       "      dtype=object),\n",
       "       ...,\n",
       "       array(['Email', 'Email', 'Interaction', 'Email', 'Email', 'END', 'END',\n",
       "       'END', 'END', 'END'], dtype=object),\n",
       "       array(['Interaction', 'Email', 'END', 'END', 'END', 'END', 'END'],\n",
       "      dtype=object),\n",
       "       array(['Interaction', 'Email', 'END', 'END', 'END', 'END', 'END'],\n",
       "      dtype=object)], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [] #np.array([])\n",
    "#prepare for MC\n",
    "for caseid in list(set(df.case_id.values)):\n",
    "    \n",
    "    trace = df.loc[df.case_id == caseid][\"task_tasksubtype\"].values\n",
    "    trace = np.append(trace,\"END\")\n",
    "    trace = np.append(trace,\"END\")\n",
    "    trace = np.append(trace,\"END\")\n",
    "    trace = np.append(trace,\"END\")\n",
    "    trace = np.append(trace,\"END\")\n",
    "    \n",
    "    #data = np.concatenate((data, trace),axis=0)\n",
    "    #data = np.append([data],[[trace]])\n",
    "    data.append(trace)\n",
    "    \n",
    "#convert from list to array\n",
    "traindata = np.asarray(data)\n",
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate markov chain with pomegranate\n",
    "\"\"\"\n",
    "\n",
    "#HOMC\n",
    "#max_trace_len = 5\n",
    "#model = pomegranate.MarkovChain.from_samples(X=traindata, \n",
    "#                                  weights=None, \n",
    "#                                  k=max_trace_len)\n",
    "\n",
    "#MC\n",
    "model = pomegranate.MarkovChain.from_samples(X=traindata)#, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"class\" : \"Distribution\",\n",
       "    \"dtype\" : \"str\",\n",
       "    \"name\" : \"DiscreteDistribution\",\n",
       "    \"parameters\" : [\n",
       "        {\n",
       "            \"Task-Reminder\" : 0.0,\n",
       "            \"END\" : 0.0,\n",
       "            \"Interaction\" : 0.9188619599578504,\n",
       "            \"Email\" : 0.08113804004214963\n",
       "        }\n",
       "    ],\n",
       "    \"frozen\" : false\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inspect\n",
    "\"\"\"\n",
    "#unconditional probabilities\n",
    "model.distributions[0]\n",
    "\n",
    "#all probabilities#\n",
    "#model.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Task-Reminder', 'Task-Reminder', '0.0909090909090909'],\n",
       " ['Task-Reminder', 'END', '0.22727272727272727'],\n",
       " ['Task-Reminder', 'Interaction', '0.04545454545454546'],\n",
       " ['Task-Reminder', 'Email', '0.6363636363636364'],\n",
       " ['END', 'Task-Reminder', '0.0'],\n",
       " ['END', 'END', '1.0'],\n",
       " ['END', 'Interaction', '0.0'],\n",
       " ['END', 'Email', '0.0'],\n",
       " ['Interaction', 'Task-Reminder', '0.001078167115902965'],\n",
       " ['Interaction', 'END', '0.02048517520215633'],\n",
       " ['Interaction', 'Interaction', '0.017250673854447448'],\n",
       " ['Interaction', 'Email', '0.9611859838274932'],\n",
       " ['Email', 'Task-Reminder', '0.005029337803855825'],\n",
       " ['Email', 'END', '0.5183012014529198'],\n",
       " ['Email', 'Interaction', '0.02179379715004191'],\n",
       " ['Email', 'Email', '0.45487566359318243']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_prob = model.distributions[1]\n",
    "\n",
    "cond_prob.to_dict()[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>to</th>\n",
       "      <th>END</th>\n",
       "      <th>Email</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Task-Reminder</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>END</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task-Reminder</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "to              END  Email  Interaction  Task-Reminder\n",
       "from                                                  \n",
       "END            1.00   0.00         0.00           0.00\n",
       "Email          0.52   0.45         0.02           0.01\n",
       "Interaction    0.02   0.96         0.02           0.00\n",
       "Task-Reminder  0.23   0.64         0.05           0.09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transition_table = pd.DataFrame(model.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "transition_table[\"prob\"] = pd.to_numeric(transition_table[\"prob\"], downcast=\"float\")\n",
    "\n",
    "adj_matrix = transition_table.pivot(index='from', columns='to', values=\"prob\").round(2)\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Email', 'END', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First-order markov chain\n",
    "\"\"\"\n",
    "\n",
    "model = pomegranate.MarkovChain.from_samples(X=traindata)\n",
    "\n",
    "predictions=[]\n",
    "num_predictions = 4\n",
    "\n",
    "for i in range(0,num_predictions):\n",
    "    \n",
    "    # sample untill length k from the markov chain\n",
    "    sample=model.sample(5)\n",
    "    print(sample)\n",
    "    predictions.append(sample)\n",
    "    \n",
    "predictions = np.asarray(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Interaction', 'Email', 'Interaction', 'Interaction', 'Interaction']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Email', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Interaction', 'Interaction', 'Email']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Interaction', 'Email']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Email', 'Interaction', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Interaction', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Interaction', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Interaction', 'Interaction', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'Interaction', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Interaction', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Interaction', 'Interaction']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Interaction', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Interaction', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'Email', 'Email']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Interaction', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Email', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'END', 'END', 'END']\n",
      "['Interaction', 'Email', 'Email', 'END', 'END']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Higher-order markov chain\n",
    "\"\"\"\n",
    "\n",
    "k = 5\n",
    "num_predictions = 200\n",
    "\n",
    "model = pomegranate.MarkovChain.from_samples(X=traindata, \n",
    "                                  weights=None, \n",
    "                                  k=k)\n",
    "predictions=[]\n",
    "\n",
    "for i in range(0,num_predictions):\n",
    "    \n",
    "    # sample untill length k from the markov chain\n",
    "    sample=model.sample(k)\n",
    "    print(sample)\n",
    "    predictions.append(sample)\n",
    "    \n",
    "predictions = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProcedure:\\n- Use transition matrices\\n- Train and holdout\\n- Compare fit in train to empirical holdout\\n    - flatten / vectorize matrices\\n    - calculate KL divergence\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Procedure:\n",
    "- Use transition matrices\n",
    "- Train and holdout\n",
    "- Compare fit in train to empirical holdout\n",
    "    - flatten / vectorize matrices\n",
    "    - calculate KL divergence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_distance():\n",
    "    DL = _\n",
    "    return DL\n",
    "\n",
    "def euclidean_distance(p,q):\n",
    "    dist = np.linalg.norm(p-q)\n",
    "    return dist\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a holdout sample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(traindata, test_size=0.3)#, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_size = 1\n",
    "\n",
    "#Train the baseline model\n",
    "model_test = pomegranate.MarkovChain.from_samples(X=X_test, \n",
    "                                  weights=None, \n",
    "                                  k=k_size)\n",
    "\n",
    "#Train the model\n",
    "model_train = pomegranate.MarkovChain.from_samples(X=X_train, \n",
    "                                  weights=None, \n",
    "                                  k=k_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate the two transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trans = pd.DataFrame(model_test.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "test_trans[\"prob\"] = pd.to_numeric(test_trans[\"prob\"], downcast=\"float\")\n",
    "\n",
    "train_trans = pd.DataFrame(model_train.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "train_trans[\"prob\"] = pd.to_numeric(train_trans[\"prob\"], downcast=\"float\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Store them so they can be used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>to</th>\n",
       "      <th>Task-Reminder</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Email</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Task-Reminder</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>END</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "to             Task-Reminder  Interaction  Email   END\n",
       "from                                                  \n",
       "Task-Reminder           0.10         0.05   0.60  0.25\n",
       "Interaction             0.00         0.02   0.96  0.02\n",
       "Email                   0.01         0.02   0.46  0.52\n",
       "END                     0.00         0.00   0.00  1.00"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix_train = train_trans.pivot(index='from', columns='to', values=\"prob\").round(2)\n",
    "adj_matrix_train = adj_matrix_train.sort_index(axis='columns', level='from', ascending=False)\n",
    "adj_matrix_train = adj_matrix_train.sort_index(axis='rows', level='from', ascending=False)\n",
    "adj_matrix_train.to_csv(\"../tables/activity_sequence_params_train.csv\")\n",
    "adj_matrix_train.to_csv(\"../tables/Final_models/activity_sequence_parameters_train.csv\")\n",
    "adj_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>to</th>\n",
       "      <th>Task-Reminder</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Email</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Task-Reminder</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>END</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "to             Task-Reminder  Interaction  Email   END\n",
       "from                                                  \n",
       "Task-Reminder            0.0         0.00   1.00  0.00\n",
       "Interaction              0.0         0.01   0.97  0.02\n",
       "Email                    0.0         0.02   0.45  0.52\n",
       "END                      0.0         0.00   0.00  1.00"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix_test = test_trans.pivot(index='from', columns='to', values=\"prob\").round(2)\n",
    "adj_matrix_test = adj_matrix_test.sort_index(axis='columns', level='from', ascending=False)\n",
    "adj_matrix_test = adj_matrix_test.sort_index(axis='rows', level='from', ascending=False)\n",
    "adj_matrix_test.to_csv(\"../tables/Final_models/activity_sequence_params_test.csv\")\n",
    "adj_matrix_train.to_csv(\"../tables/Final_models/activity_sequence_parameters_test.csv\")\n",
    "adj_matrix_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get the base rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity   \n",
       "Interaction    1226\n",
       "Email           102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ev = []\n",
    "\n",
    "for trace in X_train:\n",
    "    #print(trace[0])\n",
    "    first_ev.append(trace[0])\n",
    "\n",
    "train_bases = pd.DataFrame({\"activity\":first_ev})\n",
    "train_bases.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.92, 0.08, 0, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1744 + 154\n",
    "[np.round(1744/n,decimals=2),np.round(154/n,decimals=2),0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity   \n",
       "Interaction    518\n",
       "Email           52\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ev = []\n",
    "\n",
    "for trace in X_test:\n",
    "    #print(trace[0])\n",
    "    first_ev.append(trace[0])\n",
    "\n",
    "test_bases = pd.DataFrame({\"activity\":first_ev})\n",
    "test_bases.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91, 0.09, 0, 0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 518 + 52\n",
    "[np.round(518/n,decimals=2),np.round(52/n,decimals=2),0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Interaction</td>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Email</td>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>0.007339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>END</td>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>Interaction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Interaction</td>\n",
       "      <td>Interaction</td>\n",
       "      <td>0.016071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Email</td>\n",
       "      <td>Interaction</td>\n",
       "      <td>0.021101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>END</td>\n",
       "      <td>Interaction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>Email</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Interaction</td>\n",
       "      <td>Email</td>\n",
       "      <td>0.960714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Email</td>\n",
       "      <td>Email</td>\n",
       "      <td>0.461468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>END</td>\n",
       "      <td>Email</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Task-Reminder</td>\n",
       "      <td>END</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Interaction</td>\n",
       "      <td>END</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Email</td>\n",
       "      <td>END</td>\n",
       "      <td>0.510092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             from             to      prob\n",
       "0   Task-Reminder  Task-Reminder  0.100000\n",
       "8     Interaction  Task-Reminder  0.001786\n",
       "12          Email  Task-Reminder  0.007339\n",
       "4             END  Task-Reminder  0.000000\n",
       "2   Task-Reminder    Interaction  0.000000\n",
       "10    Interaction    Interaction  0.016071\n",
       "14          Email    Interaction  0.021101\n",
       "6             END    Interaction  0.000000\n",
       "3   Task-Reminder          Email  0.700000\n",
       "11    Interaction          Email  0.960714\n",
       "15          Email          Email  0.461468\n",
       "7             END          Email  0.000000\n",
       "1   Task-Reminder            END  0.200000\n",
       "9     Interaction            END  0.021429\n",
       "13          Email            END  0.510092\n",
       "5             END            END  1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort them so they have the same order\n",
    "train_trans = train_trans.sort_values([\"to\", \"from\"], ascending = (False, False))\n",
    "train_trans\n",
    "\n",
    "test_trans = test_trans.sort_values([\"to\", \"from\"], ascending = (False, False))\n",
    "test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize to avoid zeros\n",
    "test_prob_norm = (test_trans[\"prob\"].values+0.0001)/np.sum(test_trans[\"prob\"].values)\n",
    "train_prob_norm = (train_trans[\"prob\"].values+0.0001)/np.sum(train_trans[\"prob\"].values)\n",
    "\n",
    "#no normalization\n",
    "test_prob = test_trans[\"prob\"]\n",
    "train_prob = train_trans[\"prob\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12426761"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KL divergence: Entropy between two probability densities\n",
    "kl_divergence(train_prob_norm, \n",
    "              test_prob_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15356018"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L2 norm between two vectors\n",
    "euclidean_distance(train_prob.values, test_prob.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.083333\n",
       "8     0.000772\n",
       "12    0.004018\n",
       "4     0.000000\n",
       "2     0.083333\n",
       "10    0.017761\n",
       "14    0.022097\n",
       "6     0.000000\n",
       "3     0.583333\n",
       "11    0.961390\n",
       "15    0.451989\n",
       "7     0.000000\n",
       "1     0.250000\n",
       "9     0.020077\n",
       "13    0.521896\n",
       "5     1.000000\n",
       "Name: prob, dtype: float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.100000\n",
       "8     0.001786\n",
       "12    0.007339\n",
       "4     0.000000\n",
       "2     0.000000\n",
       "10    0.016071\n",
       "14    0.021101\n",
       "6     0.000000\n",
       "3     0.700000\n",
       "11    0.960714\n",
       "15    0.461468\n",
       "7     0.000000\n",
       "1     0.200000\n",
       "9     0.021429\n",
       "13    0.510092\n",
       "5     1.000000\n",
       "Name: prob, dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate max steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_max_steps(P,D):\n",
    "    import numpy as np\n",
    "\n",
    "    #generate the transient matrix\n",
    "    Q = P[:len(D)-1,:len(D)-1]\n",
    "\n",
    "    #get the determinant of P\n",
    "    P_det = np.linalg.det(P)\n",
    "    print(\"Det:\",str(P_det))\n",
    "\n",
    "    I = np.identity(len(Q))\n",
    "    M = np.linalg.inv((I-Q))\n",
    "\n",
    "    M = np.dot(M, np.ones(len(Q)))\n",
    "\n",
    "    n_steps = np.max(M)\n",
    "\n",
    "    print(\"expected steps:\",n_steps)\n",
    "\n",
    "    return n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Task-Reminder', 'Interaction', 'Email', 'END']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = adj_matrix_test.columns.tolist()\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1 , 0.  , 0.7 , 0.2 ],\n",
       "       [0.  , 0.02, 0.96, 0.02],\n",
       "       [0.01, 0.02, 0.46, 0.51],\n",
       "       [0.  , 0.  , 0.  , 1.  ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = adj_matrix_test.values\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>to</th>\n",
       "      <th>Task-Reminder</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Email</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Task-Reminder</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>END</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "to             Task-Reminder  Interaction  Email   END\n",
       "from                                                  \n",
       "Task-Reminder           0.10         0.00   0.70  0.20\n",
       "Interaction             0.00         0.02   0.96  0.02\n",
       "Email                   0.01         0.02   0.46  0.51\n",
       "END                     0.00         0.00   0.00  1.00"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Det: -0.0008159999\n",
      "expected steps: 2.904963357672954\n",
      "\n",
      "test\n",
      "Det: -0.00114\n",
      "expected steps: 2.991551270227804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.991551270227804"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train\")\n",
    "Get_max_steps(P=adj_matrix_train.values,D=adj_matrix_train.columns.tolist())\n",
    "print(\"\\ntest\")\n",
    "Get_max_steps(P=adj_matrix_test.values,D=adj_matrix_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det: -0.00114\n",
      "expected steps: 2.991551270227804\n"
     ]
    }
   ],
   "source": [
    "D = adj_matrix_test.columns.tolist()\n",
    "P = adj_matrix_test.values\n",
    "\n",
    "#generate the transient matrix\n",
    "Q = P[:len(D)-1,:len(D)-1]\n",
    "\n",
    "#get the determinant of P\n",
    "P_det = np.linalg.det(P)\n",
    "print(\"Det:\",str(P_det))\n",
    "\n",
    "I = np.identity(len(Q))\n",
    "M = np.linalg.inv((I-Q))\n",
    "\n",
    "M = np.dot(M, np.ones(len(Q)))\n",
    "\n",
    "n_steps = np.max(M)\n",
    "\n",
    "print(\"expected steps:\",n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected steps: 2.991551270227804\n"
     ]
    }
   ],
   "source": [
    "I = np.identity(len(Q))\n",
    "M = np.linalg.inv((I-Q))\n",
    "\n",
    "M = np.dot(M, np.ones(len(Q)))\n",
    "\n",
    "n_steps = np.max(M)\n",
    "\n",
    "print(\"expected steps:\",n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det: -0.00114\n",
      "expected steps: 2.991551270227804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.991551270227804"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Get_max_steps(P,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap the whole process\n",
    "\n",
    "- <b>Problem:</b>\n",
    "    - Want to figure out whether a _MODEL_ (first-order markov chain), trained on a train split, is equivalent to the empirical distribution in the validation split.\n",
    "\n",
    "- <b>Hypothesis:</b> \n",
    "    - The two adjacency matrices are insignificantly different from each other (approximately the same)\n",
    "\n",
    "- <b>Experiment:</b> \n",
    "    - Run N repetitions of fitting a model from different subsets of the data (bootstrapping)\n",
    "\n",
    "- <b>Test statistic:</b>\n",
    "    - T-test, to see wether mew (of all test results) is outside the 95% confidence interval around 0 (where 0 means no difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-48f22212c596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmodel_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpomegranate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMarkovChain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#########################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TF2_CUD11_CRM_PAPER\\lib\\site-packages\\pomegranate\\MarkovChain.pyx\u001b[0m in \u001b[0;36mpomegranate.MarkovChain.MarkovChain.from_samples\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TF2_CUD11_CRM_PAPER\\lib\\site-packages\\pomegranate\\MarkovChain.pyx\u001b[0m in \u001b[0;36mpomegranate.MarkovChain.MarkovChain.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TF2_CUD11_CRM_PAPER\\lib\\site-packages\\pomegranate\\MarkovChain.pyx\u001b[0m in \u001b[0;36mpomegranate.MarkovChain.MarkovChain.summarize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TF2_CUD11_CRM_PAPER\\lib\\site-packages\\pomegranate\\distributions\\DiscreteDistribution.pyx\u001b[0m in \u001b[0;36mpomegranate.distributions.DiscreteDistribution.DiscreteDistribution.summarize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TF2_CUD11_CRM_PAPER\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bootstrapping N runs\n",
    "\"\"\"\n",
    "\n",
    "kl_errors=[]\n",
    "euc_errors=[]\n",
    "\n",
    "for run in range(0, 5000):\n",
    "    \n",
    "    ############################################################################\n",
    "    # ALTERNATIVE MODELS\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # MARKOV CHAIN\n",
    "    ############################################################################\n",
    "    \n",
    "    #Draw new split from the data\n",
    "    X_train, X_test = train_test_split(traindata, test_size=0.3, random_state=run)\n",
    "    \n",
    "    \n",
    "    #########################\n",
    "    # Training\n",
    "    k_size = 1\n",
    "\n",
    "    #Train the baseline model\n",
    "    model_test = pomegranate.MarkovChain.from_samples(X=X_test, k=k_size)\n",
    "    \n",
    "    #Train the model\n",
    "    model_train = pomegranate.MarkovChain.from_samples(X=X_train, k=k_size)\n",
    "    \n",
    "    #########################\n",
    "    # transforming\n",
    "    test_trans = pd.DataFrame(model_test.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "    test_trans[\"prob\"] = pd.to_numeric(test_trans[\"prob\"], downcast=\"float\")\n",
    "    \n",
    "    test_trans = test_trans.sort_values([\"to\", \"from\"], ascending = (False, False))\n",
    "    \n",
    "    test_prob = test_trans[\"prob\"]\n",
    "    \n",
    "\n",
    "    train_trans = pd.DataFrame(model_train.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "    train_trans[\"prob\"] = pd.to_numeric(train_trans[\"prob\"], downcast=\"float\")\n",
    "    \n",
    "    train_trans = train_trans.sort_values([\"to\", \"from\"], ascending = (False, False))\n",
    "    \n",
    "    train_prob = train_trans[\"prob\"]\n",
    "    \n",
    "    # sort them so they have the same order\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Check that they are the same?!\n",
    "    \"\"\"\n",
    "    \n",
    "    #kl_error, euc_error = 999, 999\n",
    "    #kl_error, euc_error = experiment(X_train, X_test)\n",
    "    \n",
    "    if train_trans[\"from\"].values.tolist() == test_trans[\"from\"].values.tolist():\n",
    "        if train_trans[\"to\"].values.tolist() == test_trans[\"to\"].values.tolist():\n",
    "            \n",
    "            #add small value\n",
    "            train_prob = train_prob + 10e-5\n",
    "            test_prob = test_prob + 10e-5\n",
    "\n",
    "            #Normalize\n",
    "            train_prob = train_prob/np.sum(train_prob)\n",
    "            test_prob = test_prob/np.sum(test_prob)\n",
    "\n",
    "            #########################\n",
    "            # evaluation\n",
    "            kl_error = kl_divergence(train_prob.values, test_prob.values)\n",
    "            euc_error = euclidean_distance(train_prob.values, test_prob.values)\n",
    "    \n",
    "    \n",
    "    \n",
    "            kl_errors.append(kl_error)\n",
    "            euc_errors.append(euc_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(kl_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "\n",
    "mew, lower, upper = mean_confidence_interval(kl_errors, \n",
    "                                             confidence=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = kl_errors\n",
    "\n",
    "_ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
    "\n",
    "plt.axvline(x = lower, color = 'b', label = 'axvline - full height')\n",
    "plt.axvline(x = upper, color = 'b', label = 'axvline - full height')\n",
    "\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that our observation is not so unlikely to have occurred by chance. Therefore, we do not reject the null hypothesis of equal population means. If the p-value is smaller than our threshold, then we have evidence against the null hypothesis of equal population means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(kl_errors, np.zeros(len(kl_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P is very very low => H0 must go => they are not similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.775240430092787e-132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test (one sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two hypotheses for this particular one sample t-test are as follows:\n",
    "\n",
    "H0: µ = 0 (the mean entropy between the two matrices is 0)\n",
    "\n",
    "HA: µ ≠15 (the mean entropy is not 0)\n",
    "\n",
    "Because the p-value of our test (0.1201) is greater than alpha = 0.05, we fail to reject the null hypothesis of the test.\n",
    "\n",
    "We do not have sufficient evidence to say that the mean height for this particular species of plant is different from 15 inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.ttest_1samp(a=kl_errors, popmean=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the p-value of our test () is less than alpha = 0.05, we reject the null hypothesis of the test.\n",
    "\n",
    "We do not have sufficient evidence to say that the mean is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data for alternative models; here we model 1-step\n",
    "\n",
    "from_act = []\n",
    "to_act = []\n",
    "\n",
    "traces = traindata\n",
    "\n",
    "\n",
    "for i in range(0, len(traces)):\n",
    "    \n",
    "    trace = traces[i]\n",
    "    \n",
    "    for activity in range(0,len(trace)):\n",
    "        \n",
    "        if activity+1 < len(trace):\n",
    "        \n",
    "            t_0 = trace[activity]\n",
    "            t_1 = trace[activity+1]\n",
    "\n",
    "            from_act.append(t_0)\n",
    "            to_act.append(t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_traindata = pd.DataFrame({\"from\":from_act,\"to\":to_act})\n",
    "alt_traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train_y = alt_traindata[\"to\"]\n",
    "alt_train_x = alt_traindata[\"from\"] #pd.get_dummies(alt_traindata, columns=[\"from\"]).drop(\"to\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw new split from the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(alt_train_x, alt_train_y, test_size=0.3, random_state=run)\n",
    "\n",
    "x_train_activites = list(set(x_train))\n",
    "\n",
    "x_train = pd.get_dummies(x_train, columns=[\"from\"]) #.drop(\"to\",axis=1)\n",
    "x_test = pd.get_dummies(x_test, columns=[\"from\"]) #.drop(\"to\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression model pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique possible activities from the full dataset\n",
    "#activities = list(set(np.concatenate(traces).ravel().tolist()))\n",
    "#activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_activites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a input matrix for every possible (mutually exclusive) combination of input\n",
    "\"\"\"\n",
    "counterfact = pd.DataFrame({\"from\":x_train_activites})\n",
    "\n",
    "counterfact = pd.get_dummies(counterfact, columns=[\"from\"])\n",
    "counterfact.index = x_train_activites\n",
    "\n",
    "# sort so that it has ones along diagonal\n",
    "counterfact = counterfact.sort_values(by=list(counterfact.columns),\n",
    "    ascending=False,axis=0)\n",
    "\n",
    "# sorted indexes\n",
    "counterfact_rows = counterfact.index\n",
    "\n",
    "#inspect\n",
    "counterfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate columns for the transition matrix\n",
    "columns_new = [w.replace('from', 'to') for w in counterfact.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmat = pd.DataFrame(logisticRegr.predict_proba(counterfact),columns=columns_new)\n",
    "transmat.index = counterfact_rows\n",
    "transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = pd.DataFrame(model_train.distributions[1].to_dict()[\"table\"], columns=[\"from\",\"to\",\"prob\"])\n",
    "train_trans[\"prob\"] = pd.to_numeric(train_trans[\"prob\"], downcast=\"float\")\n",
    "train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans[\"prob\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "1. Wrap procedure in functions so that bootstrapping can be made easier with multiple models\n",
    "2. Generate test that ensure that matrices are identical (row-order, column-order)\n",
    "3. Perform the evaluation across multiple models\n",
    "    - Markov chain (done, baseline)\n",
    "    - Logistic regression (done)\n",
    "    - Regularized logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
